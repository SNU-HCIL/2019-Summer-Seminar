# Deep Reinforcement Learning for HCIL Masters

## 1. 개요

1. **강화학습**을 공부합니다.
2. **실습과 구현**에 집중합니다.
3. **전원 완주**를 목표로 합니다.

## 2. 계획

* 처음 5주 동안 홍콩과기대 김성훈 교수님의 강의를 듣습니다.
* 다음 2주 동안 [Open AI Gym](https://gym.openai.com/envs/Acrobot-v1/)에서 어려운 것 1개 혹은 쉬운 것 2개를 골라서 자유 구현합니다.
    * 수강생끼리는 프로젝트가 겹치지 않게 합니다.
    
회차 | 날짜 | 제목 | 발표자
-----|-----|------|-------
1 | 2019.7.15 | Dummy Q Learning | 김민지
2 | 2019.7.22 | Q-learning exploit & exploration and discounted reward | 김준회
3 | 2019.7.29 | Q-learning in nondeterministic world | 박관모
4 | 2019.8.5 | Q-network | 정석원
5 | 2019.8.12 | DQN | 최길웅
6 | 2019.8.19 | 프로젝트 구현 1 | 고형권
7 | 2019.8.26 | 프로젝트 구현 2 | 안단태

강의 동영상 및 자료는 [시즌 RL](https://hunkim.github.io/ml/) 페이지에서 참조하세요.

## 3. 진행 방식

#### 3-1. 수강생의 할 일

* 발표자를 제외한 모든 수강생은 **매주 금요일 자정까지** 실습 과제를 수행합니다.
* 또한, 코드와 수행 결과를 요약한 보고서를 발표자에게 보내야 합니다. (필수 내용만 포함해서 간단하게 써주세요)
* 과제 수행 중 질문사항은 목요일 자정 이후에 발표자에게 물어보세요!
    
#### 3-2. 발표자의 할 일 

발표자는 세미나 시간 전까지 다음을 준비해야 합니다.

* 목요일 자정 전까지 숙제를 숙지해서 수강생 질문에 대비
* 자신의 코드를 잘 정리해서(모듈화, 주석 등) 본 레포지토리에 업로드
* 수강생들의 코드를 본 레포지토리에 업로드
* 수강생들의 과제 수행률에 대한 점검
* 학습 내용에 대한 간단한 리뷰

#### 3-3. 세미나 시간에 하는 일 

세미나 시간엔 발표자의 브리핑을 듣고, 수강생들이 서로의 코드를 보면서 피드백을 주고 받습니다.


